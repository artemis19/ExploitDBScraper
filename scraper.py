#!/usr/bin/env python3

import requests
import json
import os

# Headers required to get data from ExploitDB
headers = {
    "authority": "www.exploit-db.com",
    "sec-ch-ua": '" Not;A Brand";v="99", "Google Chrome";v="97", "Chromium";v="97"',
    "accept": "application/json, text/javascript, */*; q=0.01",
    "x-requested-with": "XMLHttpRequest",
    "sec-ch-ua-mobile": "?0",
    "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.71 Safari/537.36",
    "sec-ch-ua-platform": '"Linux"',
    "sec-fetch-site": "same-origin",
    "sec-fetch-mode": "cors",
    "sec-fetch-dest": "empty",
    "referer": "https://www.exploit-db.com/",
    "accept-language": "en-US,en;q=0.9",
}

url = "https://www.exploit-db.com/"

# Number of rows we can safely request from the website
safe_retrieval_cap = 5000

# Starting position for data set to request
start_offset = 0

# File to save data to
data_json = "./exploitdb_data.json"
if os.path.exists(data_json):
    with open(data_json, "w") as filp:
        pass


def request_by_bounds(start, length):
    response = requests.get(
        url,
        headers=headers,
        params={
            "start": start,
            "length": length,
            "columns[0][data]": "id",
            "columns[1][name]": "id",
            "order[0][column]": "0",
            "order[0][dir]": "asc",
        },
    )

    if response.status_code != 200:
        print(f"[!] Error- unsuccessful request from {url}: {response.status_code}")
        exit(-1)

    try:
        retrieved_json = response.json()
    except json.decoder.JSONDecodeError as exc:
        print(f"[!] Error - failed to decode JSON: {exc}")
        exit(-1)

    return retrieved_json


# Open file
with open(data_json, "a") as filp:
    print("[+] Requesting ExploitDB data...")

    # Make one singular request
    retrieved_json = request_by_bounds(start_offset, safe_retrieval_cap)

    # Keep track of the total to match the 44,899 entries in ExploitDB
    max_rows_needed = retrieved_json["recordsTotal"]

    # Write out what we have retrieved so far and add to it as we retrieve more
    # Index at -1 to remove the last curly brace so we can add more data
    filp.write(json.dumps(retrieved_json["data"])[:-1] + ",")

    # min, max, step
    for i in range(safe_retrieval_cap, max_rows_needed, safe_retrieval_cap):
        # Allows us to keep track of the remaining rows/data entries
        remaining_rows = max_rows_needed - i
        print(f"[+] {i} -> {i+(safe_retrieval_cap-1)}")
        retrieved_json = request_by_bounds(i, safe_retrieval_cap)

        # If number remaining is more than what's retrieved, keep going!
        if remaining_rows > safe_retrieval_cap:
            filp.write(json.dumps(retrieved_json["data"])[1:-1] + ",")
        else:
            # This would indicate we are at the last row so we index appropriately
            filp.write(json.dumps(retrieved_json["data"])[1:])

print(f"[+] Wrote {max_rows_needed} data entries of ExploitDB data to {data_json}")
